在图推理算法的 FastAPI 微服务开发中，可以将离线和在线部分分离，使项目结构更加清晰。离线部分负责批量数据处理、模型推理和数据库存储，而在线部分则提供实时的 API 接口来处理用户请求。以下是符合要求的项目结构示例：

```plaintext
graph_inference_service/
├── graph_inference/               # 主程序目录
│   ├── __init__.py                # 标记为 Python 包
│   ├── main.py                    # FastAPI 应用的入口文件
│   ├── config.py                  # 配置文件，加载环境变量或其他配置项
│   ├── models/                    # 图推理算法模型相关文件
│   │   ├── __init__.py
│   │   ├── model_loader.py        # 模型加载和初始化
│   │   ├── inference.py           # 推理与预测函数
│   ├── schemas/                   # 请求和响应的数据模型
│   │   ├── __init__.py
│   │   ├── online_request.py      # 在线请求的数据模型
│   │   └── online_response.py     # 在线响应的数据模型
│   ├── services/                  # 服务层
│   │   ├── __init__.py
│   │   ├── offline_task.py        # 离线任务管理
│   │   ├── online_task.py         # 在线任务逻辑
│   ├── utils/                     # 工具模块
│   │   ├── __init__.py
│   │   └── logger.py              # 日志配置
│   ├── db/                        # 数据库连接和管理
│   │   ├── __init__.py
│   │   └── database.py            # 数据库连接、查询和写入
│   └── dependencies.py            # FastAPI 依赖项
│
├── scripts/                       # 脚本目录
│   ├── run_offline_task.py        # 离线任务的入口脚本，可定期调用
│
├── tests/                         # 测试代码
│   ├── __init__.py
│   ├── test_main.py               # 测试 API 的主要功能
│   ├── test_online_task.py        # 测试在线任务功能
│   ├── test_offline_task.py       # 测试离线任务逻辑
│   └── test_models/               # 测试模型加载、推理等
│
├── requirements.txt               # 项目依赖文件
├── .env                           # 环境变量文件（包含模型路径、数据库配置等）
├── README.md                      # 项目说明文档
└── .gitignore                     # Git 忽略文件
```

### 各文件和目录功能说明

#### 1. `main.py` - FastAPI 应用入口

设置 API 路由，主要提供在线任务接口。

```python
from fastapi import FastAPI, Depends
from graph_inference.dependencies import get_model
from graph_inference.schemas.online_request import OnlineRequest
from graph_inference.schemas.online_response import OnlineResponse
from graph_inference.services.online_task import online_prediction

app = FastAPI()

@app.post("/predict", response_model=OnlineResponse)
async def predict(request: OnlineRequest, model=Depends(get_model)):
    prediction = online_prediction(model, request)
    return prediction
```

#### 2. `config.py` - 配置文件

用于管理环境配置，包括模型路径、数据库配置、离线任务定时配置等。

```python
from pydantic import BaseSettings

class Settings(BaseSettings):
    model_path: str
    db_url: str
    offline_task_schedule: str  # Cron 表达式或定时规则
    debug: bool = False

    class Config:
        env_file = ".env"

settings = Settings()
```

#### 3. `models/model_loader.py` - 模型加载

实现图推理模型的加载。

```python
import joblib
from graph_inference.config import settings

def load_model():
    model = joblib.load(settings.model_path)
    return model
```

#### 4. `models/inference.py` - 推理和预测函数

定义用于推理的函数，供在线和离线任务调用。

```python
def predict(model, data):
    # 根据传入数据进行推理
    result = model.predict(data)
    return result
```

#### 5. `services/offline_task.py` - 离线任务管理

包含用于定期批量数据处理的任务逻辑，可以通过脚本或调度器定期运行。

```python
from graph_inference.models.model_loader import load_model
from graph_inference.models.inference import predict
from graph_inference.db.database import save_prediction_to_db
from graph_inference.config import settings

def run_offline_task():
    model = load_model()
    # 从数据源获取数据，批量处理
    data_batch = ...  # 获取批量数据
    for data in data_batch:
        result = predict(model, data)
        save_prediction_to_db(data, result)
```

#### 6. `services/online_task.py` - 在线任务逻辑

定义在线推理逻辑，用于处理单个实时请求。

```python
from graph_inference.models.inference import predict
from graph_inference.schemas.online_request import OnlineRequest

def online_prediction(model, request: OnlineRequest):
    data = request.features
    prediction = predict(model, data)
    return {"prediction": prediction}
```

#### 7. `schemas/online_request.py` 和 `schemas/online_response.py` - 请求和响应的数据模型

- `online_request.py`：定义请求数据模型

```python
from pydantic import BaseModel
from typing import List

class OnlineRequest(BaseModel):
    features: List[float]
```

- `online_response.py`：定义响应数据模型

```python
from pydantic import BaseModel

class OnlineResponse(BaseModel):
    prediction: float
```

#### 8. `db/database.py` - 数据库操作

定义数据库连接以及结果存储的相关方法。

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from graph_inference.config import settings

engine = create_engine(settings.db_url)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def save_prediction_to_db(data, prediction):
    db = SessionLocal()
    # 保存到数据库的逻辑
    db.commit()
```

#### 9. `scripts/run_offline_task.py` - 离线任务入口脚本

可以通过调度器（如 Cron 或任务调度系统）定期调用该脚本执行离线任务。

```python
from graph_inference.services.offline_task import run_offline_task

if __name__ == "__main__":
    run_offline_task()
```

#### 10. 测试代码

- `tests/test_main.py`：测试主要 API 路由。
- `tests/test_online_task.py`：测试在线任务功能。
- `tests/test_offline_task.py`：测试离线任务逻辑和数据库保存功能。
- `tests/test_models/`：测试模型加载、初始化和推理输出。

### 示例 `.env` 文件

```plaintext
MODEL_PATH="path/to/your/model.joblib"
DB_URL="sqlite:///./test.db"
OFFLINE_TASK_SCHEDULE="0 0 * * *"  # 每天午夜运行
DEBUG=True
```

### 总结

1. **在线服务**：使用 FastAPI 提供实时预测接口。
2. **离线任务**：批量处理数据、调用模型推理并将结果存入数据库。
3. **目录结构**：清晰的模块划分让离线和在线功能相对独立，方便维护和扩展。
